{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Decision trees (DSFS Chapter 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are two main kinds of decision trees depending on the type of output (numeric vs. categorical). What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are normally divided into classification trees (for categorical outputs) and regression trees (for numeric outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain in your own words: Why is entropy useful when deciding where to split the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful because it helps deciding if a decision is filtering out enough candidates. \n",
    "The closer the entropy is to 0 the lower the number of likely candidates are. \n",
    "The closer to 1 the entropy is the more candidates there are left. \n",
    "Therefore we want the ones with the lowest entropy so there is fewer choises in the next step of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why are trees prone to overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because when training the model to 100% of accuracy, there could be to much irelevante information. So when trying the data on a real set or when testing the accuracy becomes lower then 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain (in your own words) how random forests help prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forest helps by picking different decisions trees and then voting for the result at the end. This prevents overfitting by making the decission depending on a majority. This helps because the overfitted tree(s) will in most cases be overruled by the majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Building the minority report algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the category of the crimes to build a decision tree that predicts the corresponding district. You can implement the ID3 tree in the DSFS book, or use the DecisionTreeClassifier class in scikit-learn. For training, you can use 90% of the data and test the tree prediction on the remaining 10%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first we read the data\n",
    "# import csv utilities and numpy\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "incedents = {}\n",
    "incedentsSingleDistrict = {}\n",
    "incedentsDayOfWeek = {}\n",
    "incedents.update({'data' : [], 'target': []})\n",
    "incedentsSingleDistrict.update({'data' : [], 'target': []})\n",
    "incedentsDayOfWeek.update({'data' : [], 'target': []})\n",
    "with open('SFPD_Incidents_-_from_1_January_2003.csv') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        incedents['data'].append(row['Category'])\n",
    "        incedents['target'].append(row['PdDistrict'])\n",
    "        incedentsSingleDistrict['data'].append(row['Category'])\n",
    "        incedentsSingleDistrict['target'].append(row['PdDistrict'] if (row['PdDistrict']=='MISSION') else 'Other')\n",
    "        incedentsDayOfWeek['data'].append(row['DayOfWeek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from __future__ import division\n",
    "\n",
    "# convert categories and PdDistricts to ints\n",
    "categories = list(set(incedents['data']))\n",
    "incedentsX = [categories.index(incedent) for incedent in incedents['data']]\n",
    "categoriesSingleDistrict = list(set(incedentsSingleDistrict['data']))\n",
    "incedentsXSingleDistrict = [categories.index(incedent) for incedent in incedentsSingleDistrict['data']]\n",
    "categoriesDayOfWeek = list(set(incedentsDayOfWeek['data']))\n",
    "incedentsXDayOfWeek = [categoriesDayOfWeek.index(incedent) for incedent in incedentsDayOfWeek['data']]\n",
    "\n",
    "# setup the classifiers\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clfSingleDistrict = tree.DecisionTreeClassifier()\n",
    "clfDayOfWeek = tree.DecisionTreeClassifier()\n",
    "\n",
    "# split the data into 90% traning and 10% test prediction \n",
    "# For all districts\n",
    "incedentsX_train = np.array(incedentsX[:int(len(incedentsX)*0.9)])\n",
    "incedentsX_test = np.array(incedentsX[-int(len(incedentsX)*0.1):])\n",
    "incedentsY_train = np.array(incedents['target'][:int(len(incedentsX)*0.9)])\n",
    "incedentsY_test = np.array(incedents['target'][-int(len(incedentsX)*0.1):])\n",
    "\n",
    "# For a single district\n",
    "incedentsX_trainSingleDistrict = np.array(incedentsXSingleDistrict[:int(len(incedentsXSingleDistrict)*0.9)])\n",
    "incedentsX_testSingleDistrict = np.array(incedentsXSingleDistrict[-int(len(incedentsXSingleDistrict)*0.1):])\n",
    "incedentsY_trainSingleDistrict = np.array(incedentsSingleDistrict['target'][:int(len(incedentsXSingleDistrict)*0.9)])\n",
    "incedentsY_testSingleDistrict = np.array(incedentsSingleDistrict['target'][-int(len(incedentsXSingleDistrict)*0.1):])\n",
    "\n",
    "# With day of week\n",
    "incedentsX_trainDayOfWeek = np.array(incedentsXDayOfWeek[:int(len(incedentsXDayOfWeek)*0.9)])\n",
    "incedentsX_testDayOfWeek = np.array(incedentsXDayOfWeek[-int(len(incedentsXDayOfWeek)*0.1):])\n",
    "\n",
    "# initialize of new arrays\n",
    "incedentsX_train_rearranged = np.zeros((len(incedentsX_train), 1))\n",
    "incedentsX_test_rearranged = np.zeros((len(incedentsX_test), 1))\n",
    "incedentsX_train_rearrangedSingleDistrict = np.zeros((len(incedentsX_trainSingleDistrict), 1))\n",
    "incedentsX_test_rearrangedSingleDistrict = np.zeros((len(incedentsX_testSingleDistrict), 1))\n",
    "incedentsX_train_rearrangedDayOfWeek=[[] for x in range(len(incedentsX_train_rearranged))]\n",
    "incedentsX_test_rearrangedDayOfWeek=[[] for x in range(len(incedentsX_test_rearranged))]\n",
    "\n",
    "# Rearrange the training and test data to two dimentional arrays [[features],[features]]\n",
    "count =0\n",
    "for x in incedentsX_train:\n",
    "    incedentsX_train_rearranged[count] = x\n",
    "    incedentsX_train_rearrangedDayOfWeek[count] = [x,incedentsX_trainDayOfWeek[count]]\n",
    "    count +=1\n",
    "    \n",
    "count =0\n",
    "for x in incedentsX_test:\n",
    "    incedentsX_test_rearranged[count] = x\n",
    "    incedentsX_test_rearrangedDayOfWeek[count] = [x,incedentsX_testDayOfWeek[count]]\n",
    "    count +=1\n",
    "\n",
    "count =0\n",
    "for x in incedentsX_trainSingleDistrict:\n",
    "    incedentsX_train_rearrangedSingleDistrict[count] = x\n",
    "    count +=1\n",
    "    \n",
    "count =0\n",
    "for x in incedentsX_testSingleDistrict:\n",
    "    incedentsX_test_rearrangedSingleDistrict[count] = x\n",
    "    count +=1\n",
    "\n",
    "# Train the classifiers and get perdictions from the test data\n",
    "clf.fit(incedentsX_train_rearranged, incedentsY_train)\n",
    "Z = clf.predict(incedentsX_test_rearranged)\n",
    "clfSingleDistrict.fit(incedentsX_train_rearrangedSingleDistrict, incedentsY_trainSingleDistrict)\n",
    "ZSingleDistrict = clfSingleDistrict.predict(incedentsX_test_rearrangedSingleDistrict)\n",
    "clfDayOfWeek.fit(incedentsX_train_rearrangedDayOfWeek, incedentsY_train)\n",
    "ZDayOfWeek = clfDayOfWeek.predict(incedentsX_test_rearrangedDayOfWeek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the fraction of correct predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.20\n"
     ]
    }
   ],
   "source": [
    "# Check how many correct perdictions\n",
    "numbOfCorrect =0\n",
    "count=0\n",
    "for ans in Z:\n",
    "    if ans ==incedentsY_test[count]:\n",
    "        numbOfCorrect+=1\n",
    "    count+=1\n",
    "print \"{:0.2f}\".format(numbOfCorrect/len(incedentsY_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the correct predictions if you restrict the training/prediction to single districts (for example, predicting Mission vs. all other districts, etc)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.79\n"
     ]
    }
   ],
   "source": [
    "# Check how many correct perdictions\n",
    "numbOfCorrect =0\n",
    "count=0\n",
    "for ans in ZSingleDistrict:\n",
    "    if ans ==incedentsY_testSingleDistrict[count]:\n",
    "        numbOfCorrect+=1\n",
    "    count+=1\n",
    "print \"{:0.2f}\".format(numbOfCorrect/len(incedentsY_testSingleDistrict)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it to the random guess, what would you get if you'd guess a district randomly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.02\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def randomGuess(numb):\n",
    "    if numb==1:\n",
    "        return \"CENTRAL\"\n",
    "    if numb==2:\n",
    "        return \"NORTHERN\"\n",
    "    if numb==3:\n",
    "        return \"PARK\"\n",
    "    if numb==4:\n",
    "        return \"SOUTHERN\"\n",
    "    if numb==5:\n",
    "        return \"MISSION\"\n",
    "    if numb==6:\n",
    "        return \"TENDERLOIN\"\n",
    "    if numb==7:\n",
    "        return \"RICHMOND\"\n",
    "    if numb==8:\n",
    "        return \"TARAVAL\"\n",
    "    if numb==9:\n",
    "        return \"INGLESIDE\"\n",
    "    if numb==10:\n",
    "        return \"BAYVIEW\"\n",
    "    \n",
    "# Make an array of random guesses\n",
    "count=0\n",
    "incedentsX_test_random=[\"\" for x in range(len(incedentsX_test_rearranged))]\n",
    "for x in incedentsX_test_random:\n",
    "    incedentsX_test_random[count] = randomGuess(randint(1,10))\n",
    "    count +=1\n",
    "\n",
    "# Check how many correct perdictions\n",
    "numbOfCorrect =0\n",
    "count=0\n",
    "for ans in incedentsX_test_random:\n",
    "    if ans ==incedentsY_test[count]:\n",
    "        numbOfCorrect+=1\n",
    "    count+=1\n",
    "print \"{:0.2f}\".format(numbOfCorrect/len(incedentsY_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you'd guess always one of the districts (for example the district with the most crimes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.94\n"
     ]
    }
   ],
   "source": [
    "# Make an array of perdictions with the district with the most crimes\n",
    "incedentsX_test_southern=[\"SOUTHERN\" for x in range(len(incedentsX_test_rearranged))]\n",
    "    \n",
    "# Check how many correct perdictions\n",
    "numbOfCorrect =0\n",
    "count=0\n",
    "for ans in incedentsX_test_southern:\n",
    "    if ans == incedentsY_test[count]:\n",
    "        numbOfCorrect+=1\n",
    "    count+=1\n",
    "print \"{:0.2f}\".format(numbOfCorrect/len(incedentsY_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add the day of the week to the features, do any of the the performance measures improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.11\n",
      "NO THEY DO NOT\n"
     ]
    }
   ],
   "source": [
    "# Check how many correct perdictions\n",
    "numbOfCorrect =0\n",
    "count=0\n",
    "for ans in ZDayOfWeek:\n",
    "    if ans ==incedentsY_test[count]:\n",
    "        numbOfCorrect+=1\n",
    "    count+=1\n",
    "print \"{:0.2f}\".format(numbOfCorrect/len(incedentsY_test)*100)\n",
    "print \"NO THEY DO NOT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "with open(\"dot.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises: I know you read the article above, but just a few questions to make you reflect on the details of the story.\n",
    "\n",
    "### Explain what features go into the terrorist detection model\n",
    "The model looks at travel patterns, where people are traveling within a given timeframe but also how often they travel to a location of interest.\n",
    "They also look at how they use their cell phone, if it is only for incoming calls, they keep on changing their sim cards, how often they turn on/off their phone. They look at their co-travelers, how often they visits airports and overnight trips.\n",
    "\n",
    "### Which algorithm is used to detect the terrorists?\n",
    "They are using a random forest algorithm\n",
    "\n",
    "### Do you agree with the algorithm that Al-Jazeera bureau chief is a good target? Justify your answer.\n",
    "MAYBE YES NO ???\n",
    "\n",
    "### What's the size of the training set?\n",
    "Their training set is only with a relative few \"known terrorists\"\n",
    "\n",
    "### Why is it still a problem that the algorithm has a false alam rate at 0.18% at a 50% miss rate?\n",
    "This means that there would still be thousands of innocent that would be flagged as terrorists and potentially killed.\n",
    "\n",
    "\n",
    "### Do you have a better grasp of the problems with overfitting after reading this article?\n",
    "By overfitting you are trying to predict with a low training data on a high test data, this means that there would be a high percentage of false positives.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
